### 计时

内核需要记录时间的流逝，通常这是通过timer tick实现的。因为系统的时钟频率固定，因此只要记录一共发生了多少时钟中断，就知道目前已经过去了多长时间。如果采用了tickless kernel的设计，虽然每次tick之间的时间间隔不固定，但都是知道的，因此只要维护一个全局时钟，每次设置定时器，就更新这个全局时钟即可。

### deferred work，多核定时器

记录时间并不是系统的全局任务，更重要的是在过了一段时间之后执行特定的动作。任务在可以执行 task_delay 来主动休眠一段时间，也可以在执行阻塞操作的时候设置超时时间，另外用户进程也可以根据自己的需求，设置一个定时器，规定多长时间之后触发。

VxWorks就支持看门狗，可以实现这个定时功能。但是 vxworks 的看门狗固定在 cpu0 上运行，长期下来必然会让 cpu0 运行任务代码的时间缩短。当然，这和 vxworks 的设计也有关系，所有的中断都是由 cpu0 这一个 cpu 来处理的，因此时钟中断也只能运行在 cpu0 上。

不过，既然我们的OS是SMP架构，那就应该尽量对称，而且对于时钟中断来说，每个CPU都能产生，因此最直接的做法就是每个CPU负责处理自己的时钟中断。但是各个cpu处理自己的时钟中断，可能会让各个CPU不同步，随着时间发展，误差逐渐积累，导致整个系统时钟不同步。如果加上一套同步策略，又会增加复杂度。

（据说 Sun 曾经做过一个测试，结果显示，将所有中断交给一个CPU来处理更高效，因为缓存利用效率更高）。但这样的话，cpu0运行任务的时间就少了，该如何处理？我们不妨更改一下计量任务时间的方式，不再用tick数计算，而是使用架构相关的perf_counter。例如在x86架构下，可以使用time-stamp counter来计量一个任务运行了多长时间。

tick是一个非常粗略的度量，相比之下tsc就非常精细了，基本上一两条语句的差异也能体现出来。Linux的CFS策略，应该也用了类似的手段来测量任务的vruntime。